{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "269c3b67-c21f-419f-b508-25ad939d9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepSI_lite as dsi\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d2f263-ab66-4a60-8c1e-a2c2ab2da548",
   "metadata": {},
   "source": [
    "## Port Hamiltonian Neural Networks in `deepSI_lite`\n",
    "\n",
    "Model structure given by `pHNN_SUBNET`\n",
    "\n",
    "$$ \\frac{dx}{dt} = \\frac{1}{\\tau} \\left (\\left ( J(x) - R(x) \\right ) \\frac{dH}{dx} + G(x) (u - u_\\text{mean})/u_\\text{std} \\right)$$\n",
    "\n",
    "$$ (y - y_\\text{mean})/y_\\text{std} = G(x)^T \\frac{dH}{dx}  $$\n",
    "\n",
    "where \n",
    "$$G (\\text{Gnet}) : n_\\text{x} \\rightarrow n_\\text{x} \\times n_\\text{u}$$\n",
    "$$J (\\text{Jnet}) : n_\\text{x} \\rightarrow n_\\text{x} \\times n_\\text{x}\\ \\text{(skew symetric)}$$\n",
    "$$R (\\text{Rnet}) : n_\\text{x} \\rightarrow n_\\text{x} \\times n_\\text{x}\\ \\text{(semi positive def)}$$\n",
    "$$H (\\text{Hnet}) : n_\\text{x} \\rightarrow\\ \\text{scalar}$$\n",
    "$$u_\\text{mean},\\ u_\\text{std},\\ y_\\text{mean},\\ y_\\text{std}\\ \\text{given by the `norm.umean`, `norm.ustd`, ect.}$$\n",
    "also `model.integrator(f, x, u, dt)` is a function that integrates the state given a certain state derivative $f$ and input $u$ for $dt$ time. \n",
    "\n",
    "These function are constructed by default by using `MLP_res_net` as a base and than converting the output such that it adhers to the constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31124692-0273-4630-94be-c9c181f0359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4271, -0.4314, -0.4297, -0.4335, -0.4365, -0.4358, -0.4374, -0.4383,\n",
       "         -0.4407, -0.4442],\n",
       "        [ 0.1740,  0.1735,  0.1715,  0.1729,  0.1718,  0.1719,  0.1698,  0.1701,\n",
       "          0.1699,  0.1709]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm = dsi.normalization.Norm(0,1,0,1)\n",
    "na = nb = 3\n",
    "nx = 4\n",
    "nu = ny = 'scalar'\n",
    "model = dsi.models.pHNN_SUBNET(nu, ny, norm, nx, na, nb)\n",
    "\n",
    "# net(torch.randn(3,4)).shape\n",
    "r = torch.randn\n",
    "b = 2\n",
    "T = 10\n",
    "upast, ypast, ufuture, yfuture = r(b, nb), r(b, na), r(b, T), r(b, T)\n",
    "sampling_time = r(b)\n",
    "model(upast, ypast, ufuture, sampling_time=sampling_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1fdca4-c7b8-4b15-815f-68941dd4aa41",
   "metadata": {},
   "source": [
    "## Customized function for each element: \n",
    "\n",
    "Example (this will get expanded later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b02f337-ab26-48cc-ac3f-d19ce046d846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepSI_lite as dsi\n",
    "import torch\n",
    "from torch import nn\n",
    "from deepSI_lite.networks import Quadratic_net\n",
    "\n",
    "class Sym_pos_semidef_converter(nn.Module):\n",
    "    def __init__(self, net, norm='auto'):\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        nx = int(round(z.shape[1]**0.5))\n",
    "        assert nx*nx==z.shape[1], 'the output of net needs to have a sqaure number of elements to be reshaped to a square matrix'\n",
    "        A = z.view(z.shape[0], nx, nx)\n",
    "        if self.norm=='auto':\n",
    "            A = A/(((nx+2)*nx**2)**0.25) #this might not be entirely correct\n",
    "        else:\n",
    "            A = A/self.norm\n",
    "        R = torch.einsum('bik,bjk->bij', A, A)\n",
    "        return R\n",
    "\n",
    "nx = 4\n",
    "Jnet_bias = dsi.networks.Bias_net(nx*nx)\n",
    "Jnet_constant = dsi.networks.Contant_net(torch.randn(nx*nx))\n",
    "Jnet_mlp = dsi.networks.MLP_res_net(input_size=nx, output_size=nx*nx) #simple \n",
    "Jnet = dsi.networks.Sum_net([Jnet_bias, Jnet_constant, Jnet_mlp]) #add these three networks together\n",
    "Jnet = dsi.networks.Skew_sym_converter(Jnet) #x -> nx x nx \n",
    "Rnet = dsi.networks.Bias_net(nx*nx)\n",
    "Rnet = dsi.networks.Sym_pos_semidef_converter(Rnet)\n",
    "\n",
    "Hnet_depend = dsi.networks.ELU_lower_bound(dsi.networks.MLP_res_net(nx, 'scalar'), lower_bound=-100)\n",
    "Hnet_qaudratic = Quadratic_net(nx)\n",
    "Hnet = dsi.networks.Ham_converter(dsi.networks.Sum_net([Hnet_depend,Hnet_qaudratic]))\n",
    "\n",
    "nu = 'scalar'\n",
    "ny = 'scalar'\n",
    "\n",
    "norm = dsi.normalization.Norm(0,1,0,1)\n",
    "na = nb = 3\n",
    "model = dsi.models.pHNN_SUBNET(nu, ny, norm, nx, na, nb, Jnet=Jnet, Rnet=Rnet, Hnet=Hnet)\n",
    "\n",
    "# net(torch.randn(3,4)).shape\n",
    "r = torch.randn\n",
    "b = 2\n",
    "T = 10\n",
    "upast, ypast, ufuture, yfuture = r(b, nb), r(b, na), r(b, T), r(b, T)\n",
    "sampling_time = r(b)\n",
    "model(upast, ypast, ufuture, sampling_time=sampling_time).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407f7cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxtryout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
